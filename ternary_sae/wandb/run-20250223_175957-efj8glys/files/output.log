Traceback (most recent call last):
  File "/proj/berzelius-2024-336/users/x_tuhan/garage/quantizedSAE/ternary_sae/ternary_sae.py", line 111, in <module>
    model = train(dataset, config)
  File "/proj/berzelius-2024-336/users/x_tuhan/garage/quantizedSAE/ternary_sae/ternary_sae.py", line 64, in train
    model = TernarySparseAutoencoder(config["input_dim"], config["hidden_dim"]).to(device)
  File "/home/x_tuhan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
  File "/home/x_tuhan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/x_tuhan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/x_tuhan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
  File "/home/x_tuhan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1329, in convert
    return t.to(
RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
